{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithm 3\n",
    "\n",
    "![img](../assets/algorithm_3.png)\n",
    "\n",
    "In Algorithm 3, attention gets two inputs $e$ and $e_{t}$.  \n",
    "- $e$ : vector representations of the current token. \n",
    "- $e_{t}$ : vector representations of context tokens $t \\in [T]$.  \n",
    "    * context tokens are the tokens that has contextual information (eg. preceding text or the surrounding text) for predicting the current token.\n",
    "\n",
    "And its output is $\\tilde{t}$, vector representation of the token and context combined with those parameters:\n",
    "- $W_{q}, W_{k} \\in \\mathbb{R}^{d_{attn} \\times d_{in}}$\n",
    "- $b_{q}, b_{k} \\in \\mathbb{R}^{d_{attn}}$, the query and key linear projections\n",
    "- $W_{v} \\in \\mathbb{R}^{d_{out} \\times d_{in}},b_{v} \\in \\mathbb{R}^{d_{out}}$, the value linear projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention works as follows:\n",
    "1. The token currently being predicted is mapped to a *query* vector $\\bf{q} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "$$\n",
    "\\bf{q} \\leftarrow W_{q}e + b_{q}\n",
    "$$\n",
    "\n",
    "2. The tokens in the context are mapped to *key* vectors $\\bf{k}_{t} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "$$\n",
    "\\forall{t}: \\bf{k}_t \\leftarrow W_{k}e_{t} + b_{q}\n",
    "$$\n",
    "\n",
    "3. The tokens in the context are mapped to *value* vectors $\\bf{v}_{t} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "$$\n",
    "\\forall{t}: \\bf{v}_t \\leftarrow W_{v}e_{t} + b_{q}\n",
    "$$\n",
    "\n",
    "4. The inner products $\\bf{q}^{T}\\bf{k}_{t}$ are interpreted as the degree to which token $t \\in V$ is important for predicting the current token $q$.\n",
    "$$\n",
    "\\forall{t}: \\alpha_t = \\frac{\\exp({\\bf{q}^{T}\\bf{k}_{t}/\\sqrt{d_{attn}}})}{\\sum_{u}{\\exp({\\bf{q}^{T}\\bf{k}_{u}/\\sqrt{d_{attn}}})}}\n",
    "$$\n",
    "\n",
    "5. Derive a distribution over the context tokens, which is then used to combine the value vectors.\n",
    "$$\n",
    "\\text{return } \\tilde{\\bf{v}}=\\sum_{t=1}^{T}{\\alpha_{t}v_{t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight matrix and bias vectors\n",
    "\n",
    "To implement Algorithm 3, we need weight matrix and bias vector as follows:\n",
    "\n",
    "1. Query\n",
    "    - $W_{q} \\in \\mathbb{R}^{d_{attn} \\times d_{in}}$\n",
    "    - $b_{q} \\in \\mathbb{R}^{d_{attn}}$\n",
    "2. Key\n",
    "    - $W_{k} \\in \\mathbb{R}^{d_{attn} \\times d_{in}}$\n",
    "    - $b_{k} \\in \\mathbb{R}^{d_{attn}}$\n",
    "3. Value\n",
    "    - $W_{v} \\in \\mathbb{R}^{d_{out} \\times d_{in}}$\n",
    "    - $b_{v} \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "We can generalize those matrix as below:\n",
    "\n",
    "- $W \\in \\mathbb{R}^{d_{out_dim} \\times d_{in_dim}}$\n",
    "- $b \\in \\mathbb{R}^{d_{out_dim}}$\n",
    "\n",
    "So, to generate thoes weight and vectors we need two argument `in_dim` and `out_dim`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_bias(in_dim, out_dim):\n",
    "    ...\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_attn = 10\n",
    "d_in = 10\n",
    "d_out = 10\n",
    "\n",
    "query_weights, query_bias = generate_weight_bias(d_attn, d_in)\n",
    "key_weights, key_bias = generate_weight_bias(d_attn, d_in)\n",
    "value_weights, value_bias = generate_weight_bias(d_in, d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement\n",
    "### Input Samples\n",
    "Now, we will implemet attention main logics step by step.  \n",
    "Assume that we have vectors like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "current_vector = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "context_vectors = np.array(\n",
    "    [\n",
    "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
    "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Query Mapping\n",
    "Define a function that implements below:\n",
    "\n",
    "1. The token currently being predicted is mapped to a *query* vector $\\bf{q} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{q}$: `query_weights`\n",
    "    - $b_{q}$: `query_bias`\n",
    "- Currently predicted vector: `current_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mapping(current_vector, query_weights, query_bias):\n",
    "    ...\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = query_mapping(current_vector, query_weights, query_bias)\n",
    "query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Key Maping\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "2. The tokens in the context are mapped to *key* vectors $\\bf{k}_{t} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "$$\n",
    "\\forall{t}: \\bf{k}_t \\leftarrow W_{k}e_{t} + b_{q}\n",
    "$$\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{q}$: `key_weights`\n",
    "    - $b_{q}$: `key_bias`\n",
    "- Context vectors: `context_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_mapping(context_vectors, key_weights, key_bias):\n",
    "    ...\n",
    "    return key_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_vectors = key_mapping(context_vectors, key_weights, key_bias)\n",
    "key_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Value Mapping\n",
    "Define a function that implements below:\n",
    "\n",
    "3. The tokens in the context are mapped to *value* vectors $\\bf{v}_{t} \\in \\mathbb{R}^{d_{attn}}$.\n",
    "$$\n",
    "\\forall{t}: \\bf{v}_t \\leftarrow W_{v}e_{t} + b_{q}\n",
    "$$\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{q}$: `value_weights`\n",
    "    - $b_{q}$: `value_bias`\n",
    "- Context vectors: `context_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_mapping(context_vectors, value_weights, value_bias):\n",
    "    ...\n",
    "    return value_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_vectors = value_mapping(context_vectors, value_weights, value_bias)\n",
    "value_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Softmax\n",
    "Define a function that implements below:\n",
    "\n",
    "4. The inner products $\\bf{q}^{T}\\bf{k}_{t}$ are interpreted as the degree to which token $t \\in V$ is important for predicting the current token $q$.\n",
    "$$\n",
    "\\forall{t}: \\alpha_t = \\frac{\\exp({\\bf{q}^{T}\\bf{k}_{t}/\\sqrt{d_{attn}}})}{\\sum_{u}{\\exp({\\bf{q}^{T}\\bf{k}_{u}/\\sqrt{d_{attn}}})}}\n",
    "$$\n",
    "\n",
    "Function will get three arguments `query_vector`, `key_vectors` and `d_attn`.  \n",
    "Note that result of this function is equal to softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a function that implements inner product between query_vector and one key_vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_query_key(query_vector, key_vector, d_attn):\n",
    "    ...\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = inner_product_query_key(query_vector, key_vectors[0], d_attn)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, define a function that implements inner product between query_vector and all key_vectors.  \n",
    "Use `inner_product_query_key` function we have defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_query_keys(query_vector, key_vectors, d_attn):\n",
    "    ...\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of `alphas` should be eqaul to length of `context_vectors`.  \n",
    "In this tutorial it should be 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = inner_product_query_keys(query_vector, key_vectors, d_attn)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make an softmax function using `alphas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(alphas):\n",
    "    ...\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of score should be equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = softmax(alphas)\n",
    "sum(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final output\n",
    "Define a function that implements below:\n",
    "\n",
    "5. Derive a distribution over the context tokens, which is then used to combine the value vectors.\n",
    "$$\n",
    "\\text{return } \\tilde{\\bf{v}}=\\sum_{t=1}^{T}{\\alpha_{t}v_{t}}\n",
    "$$\n",
    "\n",
    "Function will get two arguments `value_vectors` and `scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_value_score(value_vectors, scores):\n",
    "    ...\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of `outputs` should be equal to `d_out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = combine_value_score(value_vectors, scores)\n",
    "len(outputs), d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "\n",
    "Now, aggregate all functions we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(\n",
    "    current_vector, context_vectors, query_weights, key_weights, value_weights, query_bias, key_bias, value_bias, d_attn\n",
    "):\n",
    "    ...\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_hidden = attention(current_vector, context_vectors, query_weights, key_weights, value_weights, query_bias, key_bias, value_bias, d_attn)\n",
    "attn_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Attention\n",
    "\n",
    "> There are many ways the basic attention mechanism is used in transformers.\n",
    "> - Bidrectional / unmasked self-attention\n",
    "> - Unidrectional / masked self-attention\n",
    "> - Cross-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Algorithm 4\n",
    "\n",
    "![img](../assets/algorithm_4.png)\n",
    "\n",
    "In Algorithm 4, masked attention gets two inputs $\\bf{X} \\in \\mathbb{R}^{d_{x} \\times l_{X}}$ and $\\bf{Z} \\in \\mathbb{R}^{d_{z} \\times l_{z}}$.\n",
    "- $\\bf{X}$ : vector representation of primary\n",
    "- $\\bf{Z}$ : vector representation of context sequence\n",
    "\n",
    "And its output $\\tilde{\\bf{V}} \\in \\mathbb{R}^{d_{out} \\times l_{z}}$, updated representations of tokens in $\\bf{X}$, folding in infromation from tokens in $\\bf{Z}$ with those parameters and hyperparameters:\n",
    "\n",
    "**Parameters**\n",
    "- $W_{q} \\in \\mathbb{R}^{d_{attn} \\times d_{X}}, b_{q} \\in \\mathbb{R}^{d_{attn}}$\n",
    "- $W_{k} \\in \\mathbb{R}^{d_{attn} \\times d_{Z}}, b_{k} \\in \\mathbb{R}^{d_{attn}}$\n",
    "- $W_{v} \\in \\mathbb{R}^{d_{out} \\times d_{Z}}, b_{v} \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "**Hyper Parameters**\n",
    "- $\\text{Mask} \\in \\{0,1\\}^{l_{Z}\\times l_{X}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Softmax function with matrix form\n",
    "\n",
    "![img](../assets/softmax.png)\n",
    "\n",
    "- Mask function with matrix form\n",
    "\n",
    "![img](../assets/mask.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked Attention works as follows:  \n",
    "1. $\\bf{Q} \\leftarrow W_{q}\\bf{X} + b_{q}\\bf{1}^T$\n",
    "2. $\\bf{K} \\leftarrow W_{k}\\bf{X} + b_{k}\\bf{1}^T$\n",
    "3. $\\bf{V} \\leftarrow W_{v}\\bf{X} + b_{v}\\bf{1}^T$\n",
    "4. $\\bf{S} \\leftarrow \\bf{K}^{T}Q$\n",
    "5. $\\forall{t_{Z},t_{X}} \\text{ if }\\neg\\text{Mask}[t_{Z}, t_{X}]$ then $S[t_{Z}, t_{X}] \\leftarrow - \\infty$\n",
    "6. $\\text{return } \\tilde{\\bf{V}}=\\bf{V} \\sdot \\text{softmax } (\\bf{S}/\\sqrt{d_{attn}})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement\n",
    "### Input Sample\n",
    "Now, we will implemet attention main logics step by step.  \n",
    "Assume that we have matrix, which row is words and column is embed, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "current_matrix = np.array(\n",
    "    [\n",
    "        [1] * 10,\n",
    "        [2] * 10,\n",
    "        [3] * 10,\n",
    "    ]\n",
    ")\n",
    "context_matrix = np.array(\n",
    "    [\n",
    "        [\n",
    "            [2] * 10,\n",
    "            [3] * 10,\n",
    "            [4] * 10,\n",
    "        ],\n",
    "        [\n",
    "            [3] * 10,\n",
    "            [4] * 10,\n",
    "            [5] * 10,\n",
    "        ],\n",
    "        [\n",
    "            [4] * 10,\n",
    "            [5] * 10,\n",
    "            [6] * 10,\n",
    "        ],\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Query Mapping\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{Q} \\leftarrow W_{q}\\bf{X} + b_{q}\\bf{1}^T\n",
    "$$\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{q}$: `query_weights`\n",
    "    - $b_{q}$: `query_bias`\n",
    "- Currently predicted matrix: `current_matrix`\n",
    "\n",
    "*Hint*: use `query_mapping` for each token and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_query_mapping(current_matrix, query_weights, query_bias):\n",
    "    ...\n",
    "    return query_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_matrix = masked_query_mapping(current_matrix, query_weights, query_bias)\n",
    "query_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`query_matrix[0]` and `query_vector` should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_matrix[0], query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Key Maping\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{K} \\leftarrow W_{k}\\bf{X} + b_{k}\\bf{1}^T\n",
    "$$\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{k}$: `key_weights`\n",
    "    - $b_{k}$: `key_bias`\n",
    "- Context matrix: `context_matrix`\n",
    "\n",
    "*Hint*: use `key_mapping` for each token and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_key_mapping(context_matrix, key_weights, key_bias):\n",
    "    ...\n",
    "    return key_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_matrix = masked_key_mapping(context_matrix, key_weights, key_bias)\n",
    "key_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`key_matrix[0]` and `key_vectors` should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_matrix[0], key_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Value Mapping\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{V} \\leftarrow W_{v}\\bf{X} + b_{v}\\bf{1}^T\n",
    "$$\n",
    "\n",
    "Function will get three arguments:\n",
    "- Parameters:\n",
    "    - $W_{v}$: `value_weights`\n",
    "    - $b_{v}$: `value_bias`\n",
    "- Context matrix: `context_matrix`\n",
    "\n",
    "*Hint*: use `value_mapping` for each token and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_value_mapping(context_matrix, value_weights, value_bias):\n",
    "    ...\n",
    "    return value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_matrix = masked_value_mapping(context_matrix, value_weights, value_bias)\n",
    "value_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_matrix[0]` and `value_vectors` should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_matrix[0], value_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calucate Score\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{S} \\leftarrow \\bf{K}^{T}Q\n",
    "$$\n",
    "\n",
    "Function will get two arguments `query_matrix`, `key_matrix`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a function that implements inner product between query_matrix and one key_matrix.  \n",
    "*Hint*: use `inner_product_query_keys` for each token with `d_attn=1` and concat results. `d_attn` will be calucated after in masked attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_query_key_matrix(query_matrix, key_matrix):\n",
    "    ...\n",
    "    return alpha_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_matrix = inner_product_query_key_matrix(query_matrix, key_matrix)\n",
    "alpha_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that there is a mask matrix below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_matrix = np.array([\n",
    "    [0]*len(context_matrix[0]),\n",
    "    [0]*len(context_matrix[0]),\n",
    "    [0]*len(context_matrix[0]),\n",
    "])\n",
    "mask_matrix[1, 1] = 1\n",
    "mask_matrix[2, 2] = 1\n",
    "mask_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\forall{t_{Z},t_{X}} \\text{ if }\\neg\\text{Mask}[t_{Z}, t_{X}] \\text{ then }S[t_{Z}, t_{X}] \\leftarrow - \\infty\n",
    "$$\n",
    "\n",
    "Function will get two arguments `alpha_matrix` and `mask_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_score(alpha_matrix, mask_matrix):\n",
    "    ...\n",
    "    return masked_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_alpha = mask_score(alpha_matrix, mask_matrix)\n",
    "masked_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Final output\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\text{return } \\tilde{\\bf{V}}=\\bf{V} \\sdot \\text{softmax } (\\bf{S}/\\sqrt{d_{attn}})\n",
    "$$\n",
    "\n",
    "Function will get three arguments `value_matrix`, `alpha_matrix` and `d_attn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, calucate softmax with `alpha_matrix`.  \n",
    "*Hint*: use `softmax` for each token and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(alpha_matrix, d_attn):\n",
    "    ...\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scores = masked_softmax(alpha_matrix, d_attn)\n",
    "masked_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`masked_scores[0]` and `scores` should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scores[0], scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next combine `value_matrix` and `masked_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_value_masked_score(value_matrix, masked_scores):\n",
    "    ...\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_outputs = combine_value_masked_score(value_matrix, masked_scores)\n",
    "masked_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`masked_outputs[0]` and `outputs` should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_outputs[0], outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "\n",
    "Now, aggregate all functions we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_attention(\n",
    "    current_matrix,\n",
    "    context_matrix,\n",
    "    mask_matrix,\n",
    "    query_weights,\n",
    "    key_weights,\n",
    "    value_weights,\n",
    "    query_bias,\n",
    "    key_bias,\n",
    "    value_bias,\n",
    "    d_attn,\n",
    "):\n",
    "    ...\n",
    "    return masked_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_attn_hidden = masked_attention(\n",
    "    current_matrix,\n",
    "    context_matrix,\n",
    "    mask_matrix,\n",
    "    query_weights,\n",
    "    key_weights,\n",
    "    value_weights,\n",
    "    query_bias,\n",
    "    key_bias,\n",
    "    value_bias,\n",
    "    d_attn,\n",
    ")\n",
    "masked_attn_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Head Attention\n",
    "\n",
    "- Algorithm 5\n",
    "\n",
    "![img](../assets/algorithm_5.png)\n",
    "\n",
    "In Algorithm 5, multi-head attention gets two inputs $\\bf{X} \\in \\mathbb{R}^{d_{x} \\times l_{X}}$ and $\\bf{Z} \\in \\mathbb{R}^{d_{z} \\times l_{z}}$.\n",
    "- $\\bf{X}$ : vector representation of primary\n",
    "- $\\bf{Z}$ : vector representation of context sequence\n",
    "\n",
    "And its output $\\tilde{\\bf{V}} \\in \\mathbb{R}^{d_{out} \\times l_{z}}$, updated representations of tokens in $\\bf{X}$, folding in infromation from tokens in $\\bf{Z}$ with those parameters and hyperparameters:\n",
    "\n",
    "**Parameters**\n",
    "- For $h \\in [H]$\n",
    "    - $W_{q}^{h} \\in \\mathbb{R}^{d_{attn} \\times d_{X}}, b_{q}^{h} \\in \\mathbb{R}^{d_{attn}}$\n",
    "    - $W_{k}^{h} \\in \\mathbb{R}^{d_{attn} \\times d_{Z}}, b_{k}^{h} \\in \\mathbb{R}^{d_{attn}}$\n",
    "    - $W_{v}^{h} \\in \\mathbb{R}^{d_{out} \\times d_{Z}}, b_{v}^{h} \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "**Hyper Parameters**\n",
    "- $H$, Number of attention heads\n",
    "- $\\text{Mask} \\in \\{0,1\\}^{l_{Z}\\times l_{X}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Head Attention works as follows:  \n",
    "1. For $h \\in [H]$  \n",
    "        $\\bf{Y}^{h} \\gets \\text{Attention}(\\bf{X},\\bf{Z}|\\bf{W}_{qkv}^{h},\\text{Mask})$\n",
    "2. $\\bf{Y} \\gets [\\bf{Y}^{1}; \\bf{Y}^{2}; ...;\\bf{Y}^{H}]$\n",
    "3. $\\text{return } \\tilde{\\bf{V}}=\\bf{W}_{0}\\bf{Y}+\\bf{b}_{0}\\bf{1}^T$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head Weight matrix and bias\n",
    "\n",
    "To implement Algorithm 5, we need $h$ set of weight matrix and bias vector as follows:\n",
    "\n",
    "- For $h \\in [H]$:\n",
    "    1. Query\n",
    "        - $W_{q}^{h} \\in \\mathbb{R}^{d_{attn} \\times d_{X}}$\n",
    "        - $b_{q}^{h} \\in \\mathbb{R}^{d_{attn}}$\n",
    "    2. Key\n",
    "        - $W_{k}^{h} \\in \\mathbb{R}^{d_{attn} \\times d_{X}}$\n",
    "        - $b_{k}^{h} \\in \\mathbb{R}^{d_{attn}}$\n",
    "    3. Value\n",
    "        - $W_{v}^{h} \\in \\mathbb{R}^{d_{mid} \\times d_{Z}}$\n",
    "        - $b_{v}^{h} \\in \\mathbb{R}^{d_{mid}}$\n",
    "- Combine weight and bias\n",
    "    - $W_{o} \\in \\mathbb{R}^{d_{out} \\times Hd_{mid}}$\n",
    "    - $b_{o} \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "To generate thoes set of weight and vectors we need four argument `n_head`, `d_attn`, `d_in` and `d_out`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a function thate generates a set of qeury, key, value weights and bias.\n",
    "\n",
    "*Hint*: use `generate_weight_bias` for haad and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_weights(d_attn, d_in, d_out):\n",
    "    ...\n",
    "    return query_dict, key_dict, value_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a function that generates $h$ sets of qeury, key, value weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_weights(n_head, d_attn, d_in, d_out):\n",
    "    ...\n",
    "    return query_weight_dict, key_weight_dict, value_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head = 4\n",
    "d_attn = 10\n",
    "d_in = 10\n",
    "d_out = 10\n",
    "query_weight_dict, key_weight_dict, value_weight_dict = multi_head_weights(n_head, d_attn, d_in, d_out)\n",
    "query_weight_dict, key_weight_dict, value_weight_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define a function thate generates combine weights and bias.  \n",
    "Its `d_in` is  `n_head` * `d_out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_weights, combine_bias = generate_weight_bias(n_head*d_out, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement\n",
    "\n",
    "### 1. Calcuate attention score for each head\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "For $h \\in [H]$  \n",
    "    $\\bf{Y}^{h} \\gets \\text{Attention}(\\bf{X},\\bf{Z}|\\bf{W}_{qkv}^{h},\\text{Mask})$\n",
    "\n",
    "*Hint*: use `masked_attention` for each head and concat results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_masked_attention(\n",
    "    current_matrix,\n",
    "    context_matrix,\n",
    "    mask_matrix,\n",
    "    query_weight_dict,\n",
    "    key_weight_dict,\n",
    "    value_weight_dict,\n",
    "    d_attn,\n",
    "    n_head,\n",
    "):\n",
    "    ...\n",
    "    return multi_head_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_outputs = multi_head_masked_attention(\n",
    "    current_matrix,\n",
    "    context_matrix,\n",
    "    mask_matrix,\n",
    "    query_weight_dict,\n",
    "    key_weight_dict,\n",
    "    value_weight_dict,\n",
    "    d_attn,\n",
    "    n_head,\n",
    ")\n",
    "multi_head_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of `multi_head_outputs` is equal to `n_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multi_head_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concat the result of each head\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{Y} \\gets [\\bf{Y}^{1}; \\bf{Y}^{2}; ...;\\bf{Y}^{H}]\n",
    "$$\n",
    "\n",
    "Concat the result of each head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_multi_head(multi_head_outputs):\n",
    "    ...\n",
    "    return concat_multi_head_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_multi_head_outputs = concat_multi_head(multi_head_outputs)\n",
    "concat_multi_head_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concat_multi_head_outputs` shape must be looks like `len(current_matrix)`, `n_head`*`n_dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_multi_head_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(current_matrix), n_head*d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combine concated result with weight and bias\n",
    "\n",
    "Define a function that implements below:\n",
    "\n",
    "$$\n",
    "\\bf{Y} \\gets [\\bf{Y}^{1}; \\bf{Y}^{2}; ...;\\bf{Y}^{H}]\n",
    "$$\n",
    "\n",
    "Concat the result of each head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_head_outputs(concat_multi_head_outputs, combine_weights, combine_bias):\n",
    "    ...\n",
    "    return combined_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_outputs = combine_multi_head_outputs(concat_multi_head_outputs, combine_weights, combine_bias)\n",
    "combined_outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2856a52edefdf1612ecc51b9a351ad923998c55f10cb9b041920567e71365ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
